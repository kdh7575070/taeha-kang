{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.17 - 인덱스 클라스 관리\n",
    "\n",
    "#인덱스클라스\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "idx1 = pd.Index([1,2,3,4])\n",
    "type(idx1) #순서번호를 관리하는 인덱스 객체 -> 원래는 시리즈객체를 만들때 직접주거나 자동으로 생성되는 방식으로 인덱스 객체에 소속됨\n",
    "#기본은 정수\n",
    "\n",
    "idx2 = pd.Index(range(1,4))\n",
    "idx2\n",
    "\n",
    "# idx1 와 idx2 의 타입은 다르다!!\n",
    "idx1.difference(idx2) #둘의 차이를 알아보자-> 근데 교집합(공통점)을 출력한다...흠... 이상한 함수다\n",
    "#inx2의 rangeindex안에 들어가면 int64형이기 떄문에 교집합은 int64인 셈이다\n",
    "\n",
    "idx_s = pd.Index(['a','b','c'])\n",
    "idx_s.values\n",
    "\n",
    "idx_f = pd.Index([2,3,1,5,4],dtype='float')\n",
    "idx_f.values\n",
    "\n",
    "#인덱스 객체는 인덱싱, 슬라이싱 모두가능\n",
    "idx1[0]\n",
    "idx_s[:]\n",
    "idx1[[0]] #팬시검색\n",
    "idx1[idx1 < 3]\n",
    "\n",
    "idx1+3 #가능 3씩증가\n",
    "\n",
    "try:\n",
    "    idx1[0] = 100\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#안된다 - 인덱스를 이런 방식을 바꿔버릴 수는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "a    2\n",
       "a    3\n",
       "a    2\n",
       "a    3\n",
       "a    4\n",
       "a    3\n",
       "a    4\n",
       "a    5\n",
       "b    3\n",
       "dtype: int32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 간의 연산\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.arange(4).reshape(2,2)\n",
    "\n",
    "s1 = pd.Series(index=list('aaab'), data = np.arange(4))\n",
    "s1\n",
    "\n",
    "s2 = pd.Series(index=list('baaa'), data = np.arange(4))\n",
    "s2\n",
    "\n",
    "s1+s2 #인덱스가 다르면 안됨 - 행렬연산이 되서 이상한 결과가 나와버린다 즉 정렬을 위해서는 맞춰줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimedeltaIndex(['-1 days +23:00:00',          '00:00:00',          '01:00:00',\n",
       "                         '02:00:00',          '03:00:00',          '04:00:00',\n",
       "                         '05:00:00',          '06:00:00',          '07:00:00',\n",
       "                         '08:00:00'],\n",
       "               dtype='timedelta64[ns]', freq='H')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#인덱스 따로 만들 수 있음\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "idx_d = pd.Index(pd.date_range('20130101',periods=3))\n",
    "idx_d.values\n",
    "\n",
    "i = pd.DatetimeIndex(['2014-08-04', '2014-09-04', '2014-10-04', '2014-11-04']) #그냥문자열 아니고 Date타입임\n",
    "data = pd.Series([0,1,2,3], index=i)\n",
    "data\n",
    "#인덱스 따로 만들 수 있음\n",
    "\n",
    "i.shape\n",
    "i.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimedeltaIndex(['-1 days +23:00:00',          '00:00:00',          '01:00:00',\n",
       "                         '02:00:00',          '03:00:00',          '04:00:00',\n",
       "                         '05:00:00',          '06:00:00',          '07:00:00',\n",
       "                         '08:00:00'],\n",
       "               dtype='timedelta64[ns]', freq='H')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#타임객체상세\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#데이객체\n",
    "dr1 = pd.date_range('2018-07-03','2018-07-10')\n",
    "dr1 #사이값이 싹 나오네\n",
    "\n",
    "dr2 = pd.date_range('2018-07-03', periods=8)\n",
    "dr2\n",
    "\n",
    "dr3 = pd.date_range('2018-07-03',periods=24, freq='H') #H는 시간단위까지?\n",
    "dr3\n",
    "dr3.to_period('D')\n",
    "\n",
    "#타임객체\n",
    "tm = pd.timedelta_range(0, periods=10, freq='H')\n",
    "tm\n",
    "tm - tm[1] #이런연산도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>좌측</th>\n",
       "      <th>우측</th>\n",
       "      <th>합산</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-03</th>\n",
       "      <td>1760.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>1708.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>3475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>3148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-06</th>\n",
       "      <td>1080.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>1191.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-08</th>\n",
       "      <td>1829.0</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>3537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-09</th>\n",
       "      <td>1759.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>3501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-10</th>\n",
       "      <td>1648.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>3235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-11</th>\n",
       "      <td>1579.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>3047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-12</th>\n",
       "      <td>1022.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-13</th>\n",
       "      <td>415.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>766.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-14</th>\n",
       "      <td>427.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-15</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>2273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-16</th>\n",
       "      <td>1559.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>3036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-17</th>\n",
       "      <td>1647.0</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>3243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-18</th>\n",
       "      <td>1449.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-19</th>\n",
       "      <td>965.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-20</th>\n",
       "      <td>586.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-21</th>\n",
       "      <td>540.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-22</th>\n",
       "      <td>1088.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>2129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-23</th>\n",
       "      <td>1263.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-24</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>2429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-25</th>\n",
       "      <td>1361.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>2713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-26</th>\n",
       "      <td>1039.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>2073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-27</th>\n",
       "      <td>289.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-28</th>\n",
       "      <td>611.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>1062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-29</th>\n",
       "      <td>1146.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-30</th>\n",
       "      <td>912.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>1735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-31</th>\n",
       "      <td>883.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-01</th>\n",
       "      <td>1061.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>2091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02</th>\n",
       "      <td>2157.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>5332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>4978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>1596.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>4088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-05</th>\n",
       "      <td>1274.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>2495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-06</th>\n",
       "      <td>1210.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>2385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>1863.0</td>\n",
       "      <td>2953.0</td>\n",
       "      <td>4816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>2089.0</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>5143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>1948.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>4833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>1535.0</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>3773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>1751.0</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>4403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12</th>\n",
       "      <td>1458.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-13</th>\n",
       "      <td>1292.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>2593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>2184.0</td>\n",
       "      <td>3259.0</td>\n",
       "      <td>5443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>2194.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>5479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>2138.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>5240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2842.0</td>\n",
       "      <td>4850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-18</th>\n",
       "      <td>2307.0</td>\n",
       "      <td>2931.0</td>\n",
       "      <td>5238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-19</th>\n",
       "      <td>1211.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>2449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-20</th>\n",
       "      <td>918.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>1825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-21</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>3087.0</td>\n",
       "      <td>5105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-22</th>\n",
       "      <td>2312.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>5787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-23</th>\n",
       "      <td>2264.0</td>\n",
       "      <td>3368.0</td>\n",
       "      <td>5632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-24</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>4845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-25</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>4045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-26</th>\n",
       "      <td>1036.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>2178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-27</th>\n",
       "      <td>1240.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>2626.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-28</th>\n",
       "      <td>1121.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>2424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>1731.0</td>\n",
       "      <td>2717.0</td>\n",
       "      <td>4448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>2024.0</td>\n",
       "      <td>3053.0</td>\n",
       "      <td>5077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>1842.0</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>4580.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2067 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                좌측      우측      합산\n",
       "Date                              \n",
       "2012-10-03  1760.0  1761.0  3521.0\n",
       "2012-10-04  1708.0  1767.0  3475.0\n",
       "2012-10-05  1558.0  1590.0  3148.0\n",
       "2012-10-06  1080.0   926.0  2006.0\n",
       "2012-10-07  1191.0   951.0  2142.0\n",
       "2012-10-08  1829.0  1708.0  3537.0\n",
       "2012-10-09  1759.0  1742.0  3501.0\n",
       "2012-10-10  1648.0  1587.0  3235.0\n",
       "2012-10-11  1579.0  1468.0  3047.0\n",
       "2012-10-12  1022.0   989.0  2011.0\n",
       "2012-10-13   415.0   351.0   766.0\n",
       "2012-10-14   427.0   271.0   698.0\n",
       "2012-10-15  1200.0  1073.0  2273.0\n",
       "2012-10-16  1559.0  1477.0  3036.0\n",
       "2012-10-17  1647.0  1596.0  3243.0\n",
       "2012-10-18  1449.0  1474.0  2923.0\n",
       "2012-10-19   965.0  1012.0  1977.0\n",
       "2012-10-20   586.0   482.0  1068.0\n",
       "2012-10-21   540.0   449.0   989.0\n",
       "2012-10-22  1088.0  1041.0  2129.0\n",
       "2012-10-23  1263.0  1237.0  2500.0\n",
       "2012-10-24  1250.0  1179.0  2429.0\n",
       "2012-10-25  1361.0  1352.0  2713.0\n",
       "2012-10-26  1039.0  1034.0  2073.0\n",
       "2012-10-27   289.0   242.0   531.0\n",
       "2012-10-28   611.0   451.0  1062.0\n",
       "2012-10-29  1146.0  1071.0  2217.0\n",
       "2012-10-30   912.0   823.0  1735.0\n",
       "2012-10-31   883.0   827.0  1710.0\n",
       "2012-11-01  1061.0  1030.0  2091.0\n",
       "...            ...     ...     ...\n",
       "2018-05-02  2157.0  3175.0  5332.0\n",
       "2018-05-03  2011.0  2967.0  4978.0\n",
       "2018-05-04  1596.0  2492.0  4088.0\n",
       "2018-05-05  1274.0  1221.0  2495.0\n",
       "2018-05-06  1210.0  1175.0  2385.0\n",
       "2018-05-07  1863.0  2953.0  4816.0\n",
       "2018-05-08  2089.0  3054.0  5143.0\n",
       "2018-05-09  1948.0  2885.0  4833.0\n",
       "2018-05-10  1535.0  2238.0  3773.0\n",
       "2018-05-11  1751.0  2652.0  4403.0\n",
       "2018-05-12  1458.0  1474.0  2932.0\n",
       "2018-05-13  1292.0  1301.0  2593.0\n",
       "2018-05-14  2184.0  3259.0  5443.0\n",
       "2018-05-15  2194.0  3285.0  5479.0\n",
       "2018-05-16  2138.0  3102.0  5240.0\n",
       "2018-05-17  2008.0  2842.0  4850.0\n",
       "2018-05-18  2307.0  2931.0  5238.0\n",
       "2018-05-19  1211.0  1238.0  2449.0\n",
       "2018-05-20   918.0   907.0  1825.0\n",
       "2018-05-21  2018.0  3087.0  5105.0\n",
       "2018-05-22  2312.0  3475.0  5787.0\n",
       "2018-05-23  2264.0  3368.0  5632.0\n",
       "2018-05-24  1990.0  2855.0  4845.0\n",
       "2018-05-25  1558.0  2487.0  4045.0\n",
       "2018-05-26  1036.0  1142.0  2178.0\n",
       "2018-05-27  1240.0  1386.0  2626.0\n",
       "2018-05-28  1121.0  1303.0  2424.0\n",
       "2018-05-29  1731.0  2717.0  4448.0\n",
       "2018-05-30  2024.0  3053.0  5077.0\n",
       "2018-05-31  1842.0  2738.0  4580.0\n",
       "\n",
       "[2067 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('D:/pandas/실습자료/실습자료/data/hanriver_bridge.csv', index_col='Date', parse_dates=True, encoding='cp949')\n",
    "                                                                                             #파싱을 데이트 타입으로 가져오겠다\n",
    "data.head()\n",
    "data.index\n",
    "data.columns = ['좌측', '우측']\n",
    "data.columns\n",
    "data['합산'] = data.eval('좌측 + 우측')\n",
    "data #원본에적용\n",
    "\n",
    "#Nan처리\n",
    "data.isnull().sum()\n",
    "data.shape\n",
    "data_dp = data.dropna()\n",
    "data_dp.isnull().sum()\n",
    "data_dp.shape\n",
    "\n",
    "#Date타입으로 형식 변경\n",
    "daily = data.resample('D').sum() #Day로 바꾸면서 24개의 행을 하나로 합침 - 행값들도 자동으로 합쳐진다\n",
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    1\n",
       "20    2\n",
       "30    3\n",
       "40    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#범주형타입 인덱스\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([1,2,3,4],index=(list('abcd')))\n",
    "a['a']\n",
    "a[0]\n",
    "a[3]\n",
    "#label이 문자열이면 인덱싱 잘 됨\n",
    "\n",
    "b = pd.Series([1,2,3,4],index=[1,2,3,4]) #인덱스 이런식으로 잡지말자 절대!!!! 이럴꺼면 차라리 비워둬서 0,1,2,3 으로\n",
    "b[3]\n",
    "b[4] #여기서부터 이상해... 명시적인지 암시적인지 구분을 못하는가 봄\n",
    "b[5] = 5 #추가는 된다!!\n",
    "b\n",
    "\n",
    "#범주형\n",
    "inx_c = pd.CategoricalIndex(list('abcd'))\n",
    "inx_c\n",
    "inx_i = pd.CategoricalIndex([10,20,30,40])\n",
    "inx_i\n",
    "\n",
    "s = pd.Series([1,2,3,4], index=inx_c)\n",
    "s.index\n",
    "s['d']\n",
    "# s['e'] 될리가 없지?\n",
    "\n",
    "ss = pd.Series([1,2,3,4], index=inx_i)\n",
    "ss.index\n",
    "ss[40]\n",
    "# ss[50] 안된다! 범주형이잖아 \n",
    "\n",
    "s.index = s.index.add_categories('e')\n",
    "s.index\n",
    "s['e'] = 5 #된다\n",
    "s\n",
    "\n",
    "ss.index = ss.index.add_categories(50)\n",
    "ss.index\n",
    "#ss[50] = 5 #읭?!?! .. 다음 예제로 극복\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "d    4\n",
       "e    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#범주형 심화 - 리스트로 타입 바꿔서 인덱스추가하는 방식\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "inx_i = pd.CategoricalIndex([10,20,30,40])\n",
    "inx_i\n",
    "\n",
    "s = pd.Series([1,2,3,4], index=inx_i)\n",
    "\n",
    "stl = s.index.tolist()\n",
    "stl\n",
    "\n",
    "s.index = stl\n",
    "s.index\n",
    "s[50] = 5\n",
    "s\n",
    "\n",
    "#원한다면 다시 Categories로 바꾸면됨 astype!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>서울</th>\n",
       "      <th>2017</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경기도</th>\n",
       "      <th>2017</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "서울  2017  9\n",
       "경기도 2017  5"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#멀티인덱스 (1) - 두개의 인덱스를 행으로 가진다\n",
    "#즉 인덱싱을 통해 데이터를 다차원스럽게 활용 (DF에 적용하면 3,4차원, 시리즈에 적용하면 2,3차원이 되겠지)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#인덱스 먼저 만들자 - 멀티아님!\n",
    "ind = [('서울',2017),('경기도',2017)]\n",
    "ind\n",
    "\n",
    "#ind를 인덱스로 객체를 만들자 (값연결)\n",
    "si = pd.Series(np.random.randint(1,10,2), index=ind) #난수생성매소드 1에서 10사이의 정수 두개\n",
    "si\n",
    "\n",
    "#si['서울'] #인덱스가 두개기 때문에 하나로 접근이 안됨\n",
    "si['서울', 2017]\n",
    "si[('서울', 2017)]\n",
    "#둘다 똑같이 나온다. 튜플 괄호를 생략할 수 있음 - 파이썬 기본문법 (패킹은 튜플로)\n",
    "\n",
    "#멀티! 인덱스를 만들자\n",
    "index = pd.MultiIndex.from_tuples(ind)\n",
    "index #레벨은 자동으로 우선순위에 따라 정렬된다, 코드의 의미는 정렬전의 위치를 말해준다고 보면됨\n",
    "\n",
    "#index를 인덱스로 객체를 만들자 (값연결)\n",
    "s = pd.Series(np.random.randint(1,10,2), index=index) #이번에는 멀티인덱스 타입의 객체를 넣는다\n",
    "s['서울'] #된다 - 훨씬효율적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second\n",
       "bar    one       0.492625\n",
       "       two       0.081122\n",
       "baz    one       0.484857\n",
       "       two      -2.961918\n",
       "foo    one       0.941514\n",
       "       two      -1.144168\n",
       "qux    one      -1.614946\n",
       "       two       1.018578\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.18 - 멀티인덱스 (1)\n",
    "\n",
    "#만드는 방식 더더\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#만드는방식 2\n",
    "arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux']),\n",
    "          np.array(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'])]\n",
    "\n",
    "#값연결\n",
    "s = pd.Series(np.random.randn(8), index=arrays)\n",
    "s\n",
    "s.index\n",
    "\n",
    "#만드는방식 3\n",
    "iterables = [['bar', 'baz', 'foo', 'qux'], ['one', 'two']]\n",
    "arrays2 = pd.MultiIndex.from_product(iterables, names=['first', 'second'])\n",
    "\n",
    "#멀티인덱스는 안바뀐다 - 프로즌 리스트 타입으로 관리되기때문\n",
    "arrays2\n",
    "arrays2.levels\n",
    "arrays2.codes\n",
    "#lavels와 codes로 관리 (이전 판다스 버전에서는 codes대신 labels 였다)\n",
    "arrays2.values\n",
    "arrays2.names\n",
    "\n",
    "#값연결\n",
    "s2 = pd.Series(np.random.randn(8), index=arrays2)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "서울  2008    30000\n",
       "    2010    37000\n",
       "부산  2008    18970\n",
       "    2010    19370\n",
       "인천  2008    20850\n",
       "    2010    25140\n",
       "dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "index = [('서울',2008),('서울',2010),('부산',2008),('부산',2010), ('인천',2008),('인천',2010)]\n",
    "mul_index = pd.MultiIndex.from_tuples(index)\n",
    "\n",
    "mul_index\n",
    "mul_index.values\n",
    "mul_index.value_counts()\n",
    "\n",
    "mul_index.levels\n",
    "mul_index.codes\n",
    "\n",
    "#값연결\n",
    "populations = [ 30000,37000, 18970, 19370, 20850, 25140]\n",
    "pop = pd.Series(populations, index=mul_index)\n",
    "pop #type(pop)은 시리즈\n",
    "\n",
    "pop['서울']\n",
    "pop['서울',2008]\n",
    "pop[:, 2010]\n",
    "\n",
    "#이거는 안된다!! 정렬이 안되있기 때문\n",
    "try :\n",
    "    pop[\"서울\" : \"인천\"]\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "\n",
    "#소팅하고 나면 된다\n",
    "pop = pop.sort_index() #default는 axis=0 \n",
    "pop[\"서울\" : \"인천\"]\n",
    "\n",
    "pop.index.names = ['시','년도']\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('철수', '컴공')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#멀티인덱스 (2) 행열 모두 (데이터프레임에) 적용! *칼럼의 이름도 인덱스 클래스로 관리가 된다!!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#멀티인덱스 두개 만들기 - 행열 각각에 적용\n",
    "r_inx = pd.MultiIndex.from_product([[2017,2018],[1,2]], names=['년도','과제점수'])\n",
    "r_inx\n",
    "\n",
    "c_inx = pd.MultiIndex.from_product([['철수','영희','지원'],['컴공','경제']], names=['학생','학과'])\n",
    "c_inx\n",
    "\n",
    "data = np.round(np.abs(np.random.randn(4,6)),1)\n",
    "data\n",
    "\n",
    "#값연결\n",
    "study_data = pd.DataFrame(data, index=r_inx, columns=c_inx)\n",
    "study_data\n",
    "\n",
    "study_data.index\n",
    "study_data.columns\n",
    "\n",
    "study_data.index.get_level_values(0) #인덱스의첫번째기준나열\n",
    "study_data.index[0] #인덱스의가장첫번째속성\n",
    "study_data.columns[1] #칼럼의두번째속성 \n",
    "study_data.index.names[1] #name속성의두번째\n",
    "study_data.values #값들\n",
    "study_data['지원'] #지원이의 데에터\n",
    "\n",
    "study_data['지원','컴공'] #지원이의 컴공데이터\n",
    "study_data.loc[:, ('지원','컴공')] #행으로 출력 - 시리즈로 나온다\n",
    "\n",
    "#칼럼이소팅안돼있지\n",
    "try :\n",
    "    study_data.loc[:2018, '철수':'영희']\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "    \n",
    "#이제돼지\n",
    "study_data = study_data.sort_index(axis=1) #axis=1 !\n",
    "study_data.sort_index(axis=1).loc[:2018, '영희':'지원']\n",
    "\n",
    "#그외 뽑아내는 기능 중요!!\n",
    "study_data.loc[pd.IndexSlice[:,1], pd.IndexSlice[:, '컴공']] #컴공만\n",
    "study_data.index.levels[0].dtype\n",
    "study_data.loc[2017,1]\n",
    "study_data.xs((2017,1)) #loc[2017,1]와 동일, 함수버전\n",
    "study_data.xs(2017)\n",
    "study_data.columns.levels[0]\n",
    "study_data.columns.levels[1]\n",
    "study_data.xs(('지원','컴공'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         d    a    b    c\n",
       "one    4.0  5.0  6.0  7.0\n",
       "three  0.0  NaN  2.0  3.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.18 - 5장 데이터 정렬 및 재구성 (일부만 떼와서 새로운 형태나 구조로 DF를 만들기)\n",
    "\n",
    "#시리즈 정렬\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#데이터만들면서시리즈연결\n",
    "obj1 = pd.Series([40,10,20,30], index=list('가나다라')) # 가 40 나 10 다 20 라 30\n",
    "obj2.sort_index() #인덱스기준 소팅 - 기본이 저장X, 기본이 오름차순\n",
    "obj1.sort_values() #밸류기준 소팅 - 기본이 저장X,기본이 오름차순\n",
    "obj1.sort_values(ascending=False) #내림차순\n",
    "#근데 값을 기준으로 소팅해버리니까 인덱스들이 이상해짐\n",
    "\n",
    "#포지션!!\n",
    "obj1.argsort() #포지션레이블을 적어준다 # 가 1 나 2 다 3 라 0\n",
    "# 무슨말?? 오름차순을 기본으로 나의 포지션 (1)이 제일먼저오고 다의 포지션 (2)가 그 다음 가의 포지션 (0)이 마지막임\n",
    "# 즉 순위정보를 포지션으로 나타내준다고 생각하면 된다\n",
    "obj1.idxmin() #최소값의 인덱스 출력\n",
    "obj1.idxmax() #최대값의 인덱스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가</th>\n",
       "      <th>나</th>\n",
       "      <th>다</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   가    나  다\n",
       "0  3   15  3\n",
       "1  3   10  5\n",
       "2  1   20  5\n",
       "3  2   15  7\n",
       "4  2  100  9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터프레임 정렬\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#데이터만들기\n",
    "data = np.arange(8).reshape(2,4)\n",
    "data\n",
    "type(data)\n",
    "\n",
    "#데이터프레임에연결\n",
    "frame = pd.DataFrame(data, index=['three','one'],columns=list('dabc'))\n",
    "frame.sort_values(by='a') #DF니까 기준 열, 즉 by라는 요소가 추가돼야함!! a열을 기준으로 오름차순으로 정렬\n",
    "frame.sort_values(by='a', ascending=False) #a열을 기준으로 내림차순으로 정렬해볼까\n",
    "\n",
    "#데이터만들기2\n",
    "data1 = data.astype(np.float)\n",
    "data1[0,1] = np.nan\n",
    "data1\n",
    "\n",
    "#데이터프레임연결2\n",
    "frame1 = pd.DataFrame(data1, index=['three','one'],columns=list('dabc'))\n",
    "frame1.sort_values('a') #by는 생략가능\n",
    "frame1.sort_values(by='a', ascending=False) #NaN은 오름/내림 차순 상관없이 언제나 마지막으로\n",
    "frame1.sort_values(by='a', na_position='first') #NaN의 위치를 이렇게 설정할 수는 있다 default가 'last'인 셈\n",
    "\n",
    "#데이터만들면서데이터프레임연결\n",
    "frame2 = pd.DataFrame([{'가':3, '나':15, '다':3},\n",
    "                      {'가':3, '나':10, '다':5},\n",
    "                      {'가':1, '나':20, '다':5},\n",
    "                      {'가':2, '나':15, '다':7},\n",
    "                      {'가':2, '나':100, '다':9}])\n",
    "#다수개의 컬럼을 기준으로 정렬할 수도 있다 그때는 리스트로 묶어서준다\n",
    "frame2.sort_values(['가','나'], ascending=False) #기준 순서는 가 먼저 ->나 다음\n",
    "frame2.sort_values(['나','가'], ascending=False) #기준 순서는 나 먼저 ->가 다음\n",
    "\n",
    "#데이터만들면서데이터프레임연결2\n",
    "frame3 = pd.DataFrame([{'가':3, '나':15, '다':3},\n",
    "                      {'가':3, '다':5, '나':10},\n",
    "                      {'가':1, '나':20, '다':5},\n",
    "                      {'나':15, '다':7, '가':2},\n",
    "                      {'가':2, '나':100, '다':9}], columns=list('다가나')) #열순서 지정도가능\n",
    "frame3.sort_index() #axis=0 가 디폴트 - 행인덱스정렬\n",
    "frame3.sort_index(axis=1) #열인덱스정렬 (가나다로)\n",
    "frame3.sort_index().sort_index(axis=1) #행인덱스정렬 후 열인덱스정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나</th>\n",
       "      <th>다</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>5.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       나     다\n",
       "a  100.0   NaN\n",
       "b    4.0  99.0\n",
       "c    5.0  99.0\n",
       "d    6.0   4.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#등수기준 정렬, 재구성\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#데이터만들기\n",
    "data = {'과제건수': [1, 5, 2, 3, 4],\n",
    "        '이름': ['길동', '옥주', '현웅', '주몽', '지원'], \n",
    "        '학번': [2012, 2012, 2013, 2014, 2014], \n",
    "        '점수': [25, 94, 57, 62, 70]}\n",
    "\n",
    "#연결\n",
    "frame = pd.DataFrame(data)\n",
    "frame['순위'] = frame['점수'].rank(ascending=False) #순위로 리턴해준다\n",
    "reframe = frame.sort_values(by='순위') #인덱스가 이상해지지? 순위를 인덱스로 해버릴까\n",
    "\n",
    "reframe.index = reframe['순위'].astype(int) #reframe.index = [1,2,3,4,5]\n",
    "reframe\n",
    "\n",
    "#데이터만들기2\n",
    "data1 = {'가' : pd.Series([1.], index=['a']),\n",
    "        '나' : pd.Series([1., 2.], index=['a', 'b']),\n",
    "        '다' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "#연결2\n",
    "df = pd.DataFrame(data1)\n",
    "df\n",
    "\n",
    "#처리하기\n",
    "df['나'] = pd.Series([3,4,5,6],index=list('abcd'),dtype='float') #덮어쓰기\n",
    "df1 = df[['나', '다']] #잘라내기\n",
    "df1.at['a','나'] = 100 #값치환\n",
    "pd.set_option('chained', None) #에러처리\n",
    "df1.at[['b','c'],['다']] = 99 #값치환 - 주피터노트에러\n",
    "df1.다 = df1.다.shift(-1) #값이동 밑에서위로 -> Nan생긴다\n",
    "df1.다 = df1.다.shift(1) #위에서밑으로 -> Nan도 같이 이동한다\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index contains duplicate entries, cannot reshape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bar</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bar    A    B    C\n",
       "foo               \n",
       "one  1.0  2.0  NaN\n",
       "two  4.0  5.0  6.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#피봇을 통한 재구조화\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'foo': ['one','one','one','two','two','two'],\n",
    "                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                    'baz': [1, 2, 3, 4, 5, 6]})\n",
    "df.pivot(index='foo', columns='bar', values='baz') #중복나는 것들끼리 짝을 맞춘다\n",
    "\n",
    "df1 = pd.DataFrame({'foo': ['one','one','one','two','two','two'],\n",
    "                           'bar': ['A', 'B', 'A', 'A', 'B', 'C'],\n",
    "                           'baz': [1, 2, 3, 4, 5, 6]})\n",
    "try : \n",
    "    df1.pivot('foo','bar','baz') #안 된다 - bar에 ABCABC 가 아니라서 이상해짐\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "    \n",
    "df1 = df1.drop_duplicates(['foo','bar']) #중복되는것 one-A 없앤다\n",
    "df1.pivot('foo','bar','baz') #이제 된다! - 누락값표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()\n",
    "titanic.count()\n",
    "titanic['survived'].count()\n",
    "titanic['survived'].sum()\n",
    "\n",
    "#그룹화처리\n",
    "titanic_s = titanic.groupby('survived').mean() #수치값인 부분을 전부 평균으로 처리\n",
    "titanic_s #생존자가 0 또는 1 이므로 두개의 행이 나온다\n",
    "\n",
    "titanic_s.pivot(index='pclass', columns='age', values='fare') #재구조화\n",
    "\n",
    "titanic_ = titanic.pivot_table(index='sex', columns='class', values='survived', aggfunc='sum') #aggfunc을 추가할 수 있음 default는 'mean'\n",
    "titanic_\n",
    "titanic_.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'stack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1b66a42a346d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweek5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mstack\u001b[0m \u001b[1;31m#type은 Series!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'stack'"
     ]
    }
   ],
   "source": [
    "#스택, 언스택을 통한 \"멀티인덱스\"로 재구조화 : 마지막 행 -> 열로 열 -> 행 으로 전치한다고 생각하면됨\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weight = pd.read_csv('D:/pandas/실습자료/실습자료/data/weight_loss.csv', encoding = 'cp949')\n",
    "weight\n",
    "\n",
    "#weight.pivot(index='이름', columns='월', values='몸무게') #월에 겹치는게 있어서 안된다\n",
    "#첫주만 뽑기\n",
    "week1 =weight.drop_duplicates(['이름','월'])\n",
    "week1\n",
    "week1.pivot(index='이름', columns='월', values='몸무게')\n",
    "week1.pivot_table(index='이름', columns='월', values='몸무게') #하나만 있으면 pivot과 동일결과\n",
    "\n",
    "#마지막주 뽑기\n",
    "week4 = weight.query('주 == \"4주\"') #판다스의 꽃 - 쿼리문\n",
    "week4\n",
    "week4.pivot(index='이름', columns='월', values='몸무게') \n",
    "week4.pivot_table(index='이름', columns='월', values='몸무게') #하나만 있으면 pivot과 동일결과\n",
    "\n",
    "#이걸 가지고 이제 stack unstack 해볼거다 #딱히 쓸모 있을까...\n",
    "\n",
    "#이름,월을 멀티인덱스 행으로 잡자\n",
    "week5 = week4.set_index(['이름','월'])\n",
    "\n",
    "#STACK (열->행으로)\n",
    "stack = week5.stack()\n",
    "stack #type은 Series!! -> 여기서 더이상스택불가\n",
    "\n",
    "stack.index.get_level_values(0)\n",
    "stack.index.get_level_values(1)\n",
    "stack.index.get_level_values(2) #스택을 쌓았기 때문에 주,몸무게가 새로운 level로 편성되었다\n",
    "\n",
    "stack.to_frame() #DataFrame으로 바꿔주려면 이렇게해야한다\n",
    "stack.index.levels\n",
    "\n",
    "#UNSTACK to be back\n",
    "back = stack.unstack()\n",
    "back # week5 == back 동일하다!!\n",
    "\n",
    "#UNSTACK (행->열으로)\n",
    "unstack = week5.unstack()\n",
    "unstack #type은 Dataframe!!\n",
    "unstack = unstack.unstack()\n",
    "unstack #전부 행이되면서 Series -> 여기서 더이상스택불가\n",
    "\n",
    "unstack.to_frame() #이상해졌음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>몸무게</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이름</th>\n",
       "      <th>월</th>\n",
       "      <th>주</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">지완</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1월</th>\n",
       "      <th>1주</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2월</th>\n",
       "      <th>1주</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3월</th>\n",
       "      <th>1주</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4월</th>\n",
       "      <th>1주</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">찬준</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1월</th>\n",
       "      <th>1주</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2월</th>\n",
       "      <th>1주</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3월</th>\n",
       "      <th>1주</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4월</th>\n",
       "      <th>1주</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2주</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3주</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4주</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          몸무게\n",
       "이름 월  주      \n",
       "지완 1월 1주   70\n",
       "      2주   69\n",
       "      3주   69\n",
       "      4주   69\n",
       "   2월 1주   69\n",
       "      2주   68\n",
       "      3주   67\n",
       "      4주   66\n",
       "   3월 1주   66\n",
       "      2주   66\n",
       "      3주   65\n",
       "      4주   64\n",
       "   4월 1주   63\n",
       "      2주   63\n",
       "      3주   63\n",
       "      4주   62\n",
       "찬준 1월 1주   60\n",
       "      2주   59\n",
       "      3주   59\n",
       "      4주   59\n",
       "   2월 1주   59\n",
       "      2주   58\n",
       "      3주   57\n",
       "      4주   56\n",
       "   3월 1주   56\n",
       "      2주   56\n",
       "      3주   55\n",
       "      4주   54\n",
       "   4월 1주   53\n",
       "      2주   53\n",
       "      3주   53\n",
       "      4주   52"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 셀프 예제\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weight = pd.read_csv('D:/pandas/실습자료/실습자료/data/weight_loss.csv', encoding = 'cp949')\n",
    "\n",
    "#테이블로 평균내기\n",
    "week = weight.pivot_table(index='이름', columns='월', values='몸무게', aggfunc='mean')\n",
    "week\n",
    "\n",
    "#그 다른 방식은???\n",
    "sortedweight = weight.sort_values(by=['이름','월','주'])\n",
    "sortedweight.reset_index(drop='False', inplace=True)\n",
    "sortedweight\n",
    "\n",
    "sortedweight = sortedweight.set_index(['이름','월','주'])\n",
    "sortedweight\n",
    "\n",
    "#뭐 이런식으로 됨..\n",
    "#주별로 평균내는거는 모르겠다@@ 부분연산?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>월</th>\n",
       "      <th>1월</th>\n",
       "      <th>2월</th>\n",
       "      <th>3월</th>\n",
       "      <th>4월</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이름</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>지완</th>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>찬준</th>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "월   1월  2월  3월  4월\n",
       "이름                \n",
       "지완  69  66  64  62\n",
       "찬준  59  56  54  52"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.20 - 데이터재구조화\n",
    "\n",
    "#스택과 언스택 활용\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weight = pd.read_csv('D:/pandas/실습자료/실습자료/data/weight_loss.csv', encoding = 'cp949')\n",
    "weight\n",
    "\n",
    "#마지막주 뽑기\n",
    "week4 = weight.query('주 == \"4주\"') #판다스의 꽃 - 쿼리문\n",
    "\n",
    "week4_s = week4['몸무게']\n",
    "week4_s\n",
    "week4_s.index = week5['몸무게'].index\n",
    "week4_s\n",
    "\n",
    "#행두개 열X -> unstack 하면 행한개 열한개\n",
    "week4_s.unstack() #type은 당연히 DF\n",
    "\n",
    "#언스택 시에 레벨을 부여하면 언스택방향을 지정할 수 있다\n",
    "week4_s.unstack(level=0) #행열바뀌는결과\n",
    "week4_s.unstack(level=1) #디폴트인셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>봄</th>\n",
       "      <th>여름</th>\n",
       "      <th>가을</th>\n",
       "      <th>겨울</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A4</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A5</td>\n",
       "      <td>B5</td>\n",
       "      <td>C5</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A6</td>\n",
       "      <td>B6</td>\n",
       "      <td>C6</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A7</td>\n",
       "      <td>B7</td>\n",
       "      <td>C7</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    봄  여름  가을  겨울\n",
       "0  A0  B0  C0  D0\n",
       "1  A1  B1  C1  D1\n",
       "2  A2  B2  C2  D2\n",
       "3  A3  B3  C3  D3\n",
       "4  A4  B4  C4  D4\n",
       "5  A4  B4  C4  D4\n",
       "6  A5  B5  C5  D5\n",
       "7  A6  B6  C6  D6\n",
       "8  A7  B7  C7  D7"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터연결\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = np.array(['봄','여름','가을','겨울'])\n",
    "data = np.array([['A0','A1','A2','A3'],\n",
    "                 ['B0','B1','B2','B3'],\n",
    "                 ['C0','C1','C2','C3'],\n",
    "                 ['D0','D1','D2','D3']])\n",
    "data1 = np.array([['A4','A5','A6','A7'], #봄\n",
    "                 ['B4','B5','B6','B7'], #여름\n",
    "                 ['C4','C5','C6','C7'], #가을\n",
    "                 ['D4','D5','D6','D7']]) #겨울\n",
    "\n",
    "df1 = pd.DataFrame(data.T,columns=columns)\n",
    "df1\n",
    "df2 = pd.DataFrame(data1.T, columns=columns) #전치해서 넣어야 원래대로 들어간다\n",
    "df2\n",
    "\n",
    "#행으로접합\n",
    "df_con = pd.concat([df1,df2])\n",
    "df_con #접합! 인덱스가 이상하지\n",
    "index_r = list(range(0,8))\n",
    "df_con.index = index_r #직접넣어주기\n",
    "df_con\n",
    "\n",
    "#이걸 자동으로할려면\n",
    "df_con = pd.concat([df1,df2], ignore_index=True) #default는 false겠지\n",
    "df_con\n",
    "\n",
    "#열으로접함\n",
    "df_h = pd.concat([df1,df2], axis=1, ignore_index=True) #default는 false겠지\n",
    "df_h\n",
    "\n",
    "#데이터 단순추가\n",
    "df11 = df1.copy() #copy가 없어도 되지만 기왕이면 함수쓰는거 체화해라\n",
    "df11.loc[4] = ['A4','B4','C4','D4'] #4번째 행 추가!\n",
    "df11\n",
    "\n",
    "#메소드로추가\n",
    "df111 = df11.append({'봄':'A5','여름':'B5','가을':'C5','겨울':'D5'}, ignore_index=True) #ignore_index 안쓰면 에러난다\n",
    "df111\n",
    "\n",
    "#concat대신 append 메소드를 쓸 수도 있다!\n",
    "df11.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>봄_lx</th>\n",
       "      <th>여름_lx</th>\n",
       "      <th>가을</th>\n",
       "      <th>겨울</th>\n",
       "      <th>봄_rx</th>\n",
       "      <th>여름_rx</th>\n",
       "      <th>춘분</th>\n",
       "      <th>추분</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "      <td>A8</td>\n",
       "      <td>B8</td>\n",
       "      <td>E8</td>\n",
       "      <td>F8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "      <td>A9</td>\n",
       "      <td>B9</td>\n",
       "      <td>E9</td>\n",
       "      <td>F9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>D2</td>\n",
       "      <td>A10</td>\n",
       "      <td>B10</td>\n",
       "      <td>E10</td>\n",
       "      <td>F10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "      <td>A11</td>\n",
       "      <td>B11</td>\n",
       "      <td>E11</td>\n",
       "      <td>F11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  봄_lx 여름_lx  가을  겨울 봄_rx 여름_rx   춘분   추분\n",
       "0   A0    B0  C0  D0   A8    B8   E8   F8\n",
       "1   A1    B1  C1  D1   A9    B9   E9   F9\n",
       "2   A2    B2  C2  D2  A10   B10  E10  F10\n",
       "3   A3    B3  C3  D3  A11   B11  E11  F11"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 조인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns3 = np.array(['봄','여름','춘분','추분'])\n",
    "data3 = np.array([['A8','A9','A10','A11'],\n",
    "                 ['B8','B9','B10','B11'],\n",
    "                 ['E8','E9','E10','E11'],\n",
    "                 ['F8','F9','F10','F11']])\n",
    "\n",
    "df3 = pd.DataFrame(data3.T,columns=columns3)\n",
    "df3\n",
    "\n",
    "df4 = pd.concat([df1,df3], join='inner',ignore_index=True) #공통 레이블의 칼럼으로 쪼인\n",
    "df5 = pd.concat([df1,df3], axis=1, join='inner') #공통 레이블의 인덱스로 쪼인\n",
    "df6 = pd.concat([df1,df3], axis=1, join='outer') #단순히 접합 - default가 outer겠지 여기선 둘다 동일\n",
    "\n",
    "pd.concat([df1,df3], axis=1, keys=['사계절'], join='inner') #열 이름 주기 -> 첫번째 데이터프레임만보이네\n",
    "pd.concat([df1,df3], axis=1, keys=['사계절','춘추분'], join='inner') #열 이름 두개 주기 -> 이제 접합 둘다보인다\n",
    "\n",
    "#아예 join 메서드도 있다 -> axis = 1 이 default인 듯? 그러니 둘다 동일, 중복값을 lx는 왼쪽을 rx는 오른쪽을 처리\n",
    "df1.join(df3, how='inner', lsuffix='_lx', rsuffix='_rx') #inner로 하면 ? \n",
    "df1.join(df3, how='outer', lsuffix='_lx', rsuffix='_rx') #outer로 하면 ?\n",
    "\n",
    "#조인할 키를 주어 같은 값이 없을 때 inner은 열의 이름만, outer은 전체가 나오는데 deprecated 된 듯. concat 쓰면 되지 굳이 쓸필요없다\n",
    "#df1.join(df3, on='봄', how='inner', lsuffix='_lx', rsuffix='_rx')\n",
    "#df1.join(df3, on='봄', how='outer', lsuffix='_lx', rsuffix='_rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_Eng</th>\n",
       "      <th>변수이름</th>\n",
       "      <th>영어명과 개봉일자</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>할로우 차일드</td>\n",
       "      <td>The Hollow Child</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>죽음의 리무진</td>\n",
       "      <td>Glass Coffin</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>극장판 도라에몽: 진구의 보물섬</td>\n",
       "      <td>NaN</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>명탐정 코난 : 제로의 집행인</td>\n",
       "      <td>Detective Conan: Zero the Enforcer</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>살아남은 아이</td>\n",
       "      <td>Last Child</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>인공지능 섹스돌</td>\n",
       "      <td>NaN</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>엄마의 유혹</td>\n",
       "      <td>NaN</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>섹스-이웃집 여자-감독판</td>\n",
       "      <td>NaN</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>부드러운 여주인:단단한 물건을 원해</td>\n",
       "      <td>Okamisan 01</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>동창회:그녀와 하던 날</td>\n",
       "      <td>Rape Gurui</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>금지된 섹스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>맘마미아!2</td>\n",
       "      <td>MAMMA MIA! HERE WE GO AGAIN</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>산책하는 침략자</td>\n",
       "      <td>Before We Vanish</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>호스틸</td>\n",
       "      <td>Hostile</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>더 스퀘어</td>\n",
       "      <td>The Square</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>나를 차버린 스파이</td>\n",
       "      <td>The Spy Who Dumped Me</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>주피터스 문</td>\n",
       "      <td>Jupiter's Moon</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>휘트니</td>\n",
       "      <td>Whitney</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>원초적 비디오 테이프</td>\n",
       "      <td>Amateur</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>목격자</td>\n",
       "      <td>The Witness</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>공작</td>\n",
       "      <td>The Spy Gone North</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>너의 결혼식</td>\n",
       "      <td>On Your Wedding Day</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>몬스터 헌트2: 요괴사냥단</td>\n",
       "      <td>Monster Hunt 2</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>몬스터 호텔 3</td>\n",
       "      <td>Hotel Transylvania 3: A Monster Vacation</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>더 시크릿 하우스</td>\n",
       "      <td>Marrowbone</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>훔쳐보는 쉐어 하우스</td>\n",
       "      <td>Girls Share A Flat 4</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>해외유학녀의 마사지</td>\n",
       "      <td>Populer beauty massage into a study abroad fru...</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>폭주미망인-다빌려드립니다</td>\n",
       "      <td>Widow boarding house? I also lend a valley</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>정사 : 친구의 엄마 2 무삭제</td>\n",
       "      <td>NaN</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>인형같은 애인클럽</td>\n",
       "      <td>Makeover dolls Fingertips that love limbs</td>\n",
       "      <td>produce_year</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>20대 같은 40대 미시녀</td>\n",
       "      <td>The reason I remove the wedding ring</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>여형사의 은밀한 수사</td>\n",
       "      <td>Marubou no Onna</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>어쌔신 크리드</td>\n",
       "      <td>Assassin's Creed</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>세상의 모든 엄마와 딸들</td>\n",
       "      <td>Mothers and Daughters</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>반지의 제왕 : 반지원정대 (확장판)</td>\n",
       "      <td>The Lord Of The Rings : The Fellowship Of The ...</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>너브</td>\n",
       "      <td>Nerve</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>사랑하기 때문에</td>\n",
       "      <td>BECAUSE I LOVE YOU</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>옆집 여자: 처음엔 거부 나증엔 신음</td>\n",
       "      <td>Namaikinadantituma</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>밀애: 시아버지</td>\n",
       "      <td>Mesunonioi</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>리벤지포르노 페인트 잇 블랙</td>\n",
       "      <td>Revenge Porno PAINT IT BLACK</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>내 아내의 불륜</td>\n",
       "      <td>Soputotuma</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>추천 극상 오일마사지</td>\n",
       "      <td>Suddenly, I meet with my son. We rut. Satsuki ...</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5636</th>\n",
       "      <td>일본 온천 여행기</td>\n",
       "      <td>The dairy of lonely woman Beautifully bloom in...</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>엘리미네이터</td>\n",
       "      <td>Eliminators</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5638</th>\n",
       "      <td>소림사 무림 탐정-취의전장</td>\n",
       "      <td>Murger at the Lending House</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>선녀 강림 - 평화를 위해</td>\n",
       "      <td>Sexy girl party 4</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>패신저스</td>\n",
       "      <td>PASSENGERS</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>야쿠자의 여자: 은밀한 유혹</td>\n",
       "      <td>Japanese mafia Women 7</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5642</th>\n",
       "      <td>쇼다운 인 마닐라</td>\n",
       "      <td>Showdown in Manila</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>사다코 대 카야코</td>\n",
       "      <td>Sadako vs Kayako</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>비밀객잔의 결투</td>\n",
       "      <td>The Expert of Gangster Inn</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>더 마인즈 아이</td>\n",
       "      <td>The Mind's Eye</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>굶주린 여신: 양기흡수</td>\n",
       "      <td>Eromegami</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>하드코어 미망인</td>\n",
       "      <td>Sexy girl party 5</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5648</th>\n",
       "      <td>중년남과 고양이 여인의 동거</td>\n",
       "      <td>Domestic cat</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>여간호사의 쾌감</td>\n",
       "      <td>Sexy nurse 3</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>엑소시즘 2017</td>\n",
       "      <td>Evil Born (12/12/12)</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>선배부인과 비밀공유</td>\n",
       "      <td>The glossy and beautifl widow \"I'm sorry, hone...</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>불륜녀의 황홀한 입맞춤</td>\n",
       "      <td>Affair party</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>대머리 오일마사지사</td>\n",
       "      <td>Lonely aunt Confessions of abstinence Miku Aoki</td>\n",
       "      <td>open_date</td>\n",
       "      <td>20170102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5654 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                          title_Eng  \\\n",
       "0                  할로우 차일드                                   The Hollow Child   \n",
       "1                  죽음의 리무진                                       Glass Coffin   \n",
       "2        극장판 도라에몽: 진구의 보물섬                                                NaN   \n",
       "3         명탐정 코난 : 제로의 집행인                 Detective Conan: Zero the Enforcer   \n",
       "4                  살아남은 아이                                         Last Child   \n",
       "5                 인공지능 섹스돌                                                NaN   \n",
       "6                   엄마의 유혹                                                NaN   \n",
       "7            섹스-이웃집 여자-감독판                                                NaN   \n",
       "8      부드러운 여주인:단단한 물건을 원해                                        Okamisan 01   \n",
       "9             동창회:그녀와 하던 날                                         Rape Gurui   \n",
       "10                  금지된 섹스                                                NaN   \n",
       "11                  맘마미아!2                        MAMMA MIA! HERE WE GO AGAIN   \n",
       "12                산책하는 침략자                                   Before We Vanish   \n",
       "13                     호스틸                                            Hostile   \n",
       "14                   더 스퀘어                                         The Square   \n",
       "15              나를 차버린 스파이                              The Spy Who Dumped Me   \n",
       "16                  주피터스 문                                     Jupiter's Moon   \n",
       "17                     휘트니                                            Whitney   \n",
       "18             원초적 비디오 테이프                                            Amateur   \n",
       "19                     목격자                                        The Witness   \n",
       "20                      공작                                 The Spy Gone North   \n",
       "21                  너의 결혼식                                On Your Wedding Day   \n",
       "22          몬스터 헌트2: 요괴사냥단                                     Monster Hunt 2   \n",
       "23                몬스터 호텔 3           Hotel Transylvania 3: A Monster Vacation   \n",
       "24               더 시크릿 하우스                                         Marrowbone   \n",
       "25             훔쳐보는 쉐어 하우스                               Girls Share A Flat 4   \n",
       "26              해외유학녀의 마사지  Populer beauty massage into a study abroad fru...   \n",
       "27           폭주미망인-다빌려드립니다         Widow boarding house? I also lend a valley   \n",
       "28       정사 : 친구의 엄마 2 무삭제                                                NaN   \n",
       "29               인형같은 애인클럽          Makeover dolls Fingertips that love limbs   \n",
       "...                    ...                                                ...   \n",
       "5624        20대 같은 40대 미시녀               The reason I remove the wedding ring   \n",
       "5625           여형사의 은밀한 수사                                    Marubou no Onna   \n",
       "5626               어쌔신 크리드                                   Assassin's Creed   \n",
       "5627         세상의 모든 엄마와 딸들                              Mothers and Daughters   \n",
       "5628  반지의 제왕 : 반지원정대 (확장판)  The Lord Of The Rings : The Fellowship Of The ...   \n",
       "5629                    너브                                              Nerve   \n",
       "5630              사랑하기 때문에                                 BECAUSE I LOVE YOU   \n",
       "5631  옆집 여자: 처음엔 거부 나증엔 신음                                 Namaikinadantituma   \n",
       "5632              밀애: 시아버지                                         Mesunonioi   \n",
       "5633       리벤지포르노 페인트 잇 블랙                       Revenge Porno PAINT IT BLACK   \n",
       "5634              내 아내의 불륜                                         Soputotuma   \n",
       "5635           추천 극상 오일마사지  Suddenly, I meet with my son. We rut. Satsuki ...   \n",
       "5636             일본 온천 여행기  The dairy of lonely woman Beautifully bloom in...   \n",
       "5637                엘리미네이터                                        Eliminators   \n",
       "5638        소림사 무림 탐정-취의전장                        Murger at the Lending House   \n",
       "5639        선녀 강림 - 평화를 위해                                  Sexy girl party 4   \n",
       "5640                  패신저스                                         PASSENGERS   \n",
       "5641       야쿠자의 여자: 은밀한 유혹                             Japanese mafia Women 7   \n",
       "5642             쇼다운 인 마닐라                                 Showdown in Manila   \n",
       "5643             사다코 대 카야코                                   Sadako vs Kayako   \n",
       "5644              비밀객잔의 결투                         The Expert of Gangster Inn   \n",
       "5645              더 마인즈 아이                                     The Mind's Eye   \n",
       "5646          굶주린 여신: 양기흡수                                          Eromegami   \n",
       "5647              하드코어 미망인                                  Sexy girl party 5   \n",
       "5648       중년남과 고양이 여인의 동거                                       Domestic cat   \n",
       "5649              여간호사의 쾌감                                       Sexy nurse 3   \n",
       "5650             엑소시즘 2017                               Evil Born (12/12/12)   \n",
       "5651            선배부인과 비밀공유  The glossy and beautifl widow \"I'm sorry, hone...   \n",
       "5652          불륜녀의 황홀한 입맞춤                                       Affair party   \n",
       "5653            대머리 오일마사지사    Lonely aunt Confessions of abstinence Miku Aoki   \n",
       "\n",
       "              변수이름  영어명과 개봉일자  \n",
       "0     produce_year       2017  \n",
       "1     produce_year       2016  \n",
       "2     produce_year       2018  \n",
       "3     produce_year       2018  \n",
       "4     produce_year       2017  \n",
       "5     produce_year       2018  \n",
       "6     produce_year       2018  \n",
       "7     produce_year       2018  \n",
       "8     produce_year       2017  \n",
       "9     produce_year       2016  \n",
       "10    produce_year       2018  \n",
       "11    produce_year       2018  \n",
       "12    produce_year       2017  \n",
       "13    produce_year       2017  \n",
       "14    produce_year       2017  \n",
       "15    produce_year       2017  \n",
       "16    produce_year       2017  \n",
       "17    produce_year       2018  \n",
       "18    produce_year       2016  \n",
       "19    produce_year       2017  \n",
       "20    produce_year       2017  \n",
       "21    produce_year       2017  \n",
       "22    produce_year       2017  \n",
       "23    produce_year       2018  \n",
       "24    produce_year       2017  \n",
       "25    produce_year       2017  \n",
       "26    produce_year       2017  \n",
       "27    produce_year       2017  \n",
       "28    produce_year       2018  \n",
       "29    produce_year       2017  \n",
       "...            ...        ...  \n",
       "5624     open_date   20170110  \n",
       "5625     open_date   20170111  \n",
       "5626     open_date   20170111  \n",
       "5627     open_date   20170111  \n",
       "5628     open_date   20170111  \n",
       "5629     open_date   20170111  \n",
       "5630     open_date   20170104  \n",
       "5631     open_date   20170106  \n",
       "5632     open_date   20170106  \n",
       "5633     open_date   20170106  \n",
       "5634     open_date   20170106  \n",
       "5635     open_date   20170105  \n",
       "5636     open_date   20170105  \n",
       "5637     open_date   20170105  \n",
       "5638     open_date   20170105  \n",
       "5639     open_date   20170105  \n",
       "5640     open_date   20170104  \n",
       "5641     open_date   20170104  \n",
       "5642     open_date   20170104  \n",
       "5643     open_date   20170104  \n",
       "5644     open_date   20170104  \n",
       "5645     open_date   20170104  \n",
       "5646     open_date   20170104  \n",
       "5647     open_date   20170102  \n",
       "5648     open_date   20170102  \n",
       "5649     open_date   20170102  \n",
       "5650     open_date   20170102  \n",
       "5651     open_date   20170102  \n",
       "5652     open_date   20170102  \n",
       "5653     open_date   20170102  \n",
       "\n",
       "[5654 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#여러 열을 하나로 통합\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "movie = pd.read_csv('D:/pandas/실습자료/실습자료/data/korea_movie_list.csv',encoding='cp949')\n",
    "movie.columns\n",
    "\n",
    "df_ml = pd.melt(movie,id_vars=['title'], value_vars=['title_Eng']) #고정시킬 열을 id에, 변수로 삼을 것을 value에 할당\n",
    "df_ml #title_Eng라는 변수명이 variable이라는 열에 공통적으로 들어가고, 그 행을 요소들은 변수로서 value열에 할당된다\n",
    "df_ml = pd.melt(movie,id_vars=['title'], value_vars=['title_Eng'], var_name='영어이름', value_name='영어명')\n",
    "df_ml #variable과 value의 이름을 부여한다\n",
    "df_ml.isnull().sum() #누락값확인\n",
    "\n",
    "df_ml = pd.melt(movie,id_vars=['title', 'title_Eng'], value_vars=['open_date'], var_name='변수이름', value_name='영어명과 개봉일자') #date를 변수\n",
    "\n",
    "#열 통합!\n",
    "df_ml = pd.melt(movie,id_vars=['title', 'title_Eng'], value_vars=['produce_year','open_date'], var_name='변수이름', value_name='영어명과 개봉일자')\n",
    "df_ml # 이게 핵심이다!!! value값을 두개로 줬더니 1~2826 까지는 변수이름 produce_year에 묶인 첫번째 밸류로 이후는 open_date에 묶인 두번째 밸류로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>produce_year</th>\n",
       "      <th>produce_state</th>\n",
       "      <th>title</th>\n",
       "      <th>title_Eng</th>\n",
       "      <th>show_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>할로우 차일드</td>\n",
       "      <td>The Hollow Child</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>죽음의 리무진</td>\n",
       "      <td>Glass Coffin</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>극장판 도라에몽: 진구의 보물섬</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>명탐정 코난 : 제로의 집행인</td>\n",
       "      <td>Detective Conan: Zero the Enforcer</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>살아남은 아이</td>\n",
       "      <td>Last Child</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉</td>\n",
       "      <td>인공지능 섹스돌</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉</td>\n",
       "      <td>엄마의 유혹</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉</td>\n",
       "      <td>섹스-이웃집 여자-감독판</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉</td>\n",
       "      <td>부드러운 여주인:단단한 물건을 원해</td>\n",
       "      <td>Okamisan 01</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>동창회:그녀와 하던 날</td>\n",
       "      <td>Rape Gurui</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉</td>\n",
       "      <td>금지된 섹스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>맘마미아!2</td>\n",
       "      <td>MAMMA MIA! HERE WE GO AGAIN</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>산책하는 침략자</td>\n",
       "      <td>Before We Vanish</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>호스틸</td>\n",
       "      <td>Hostile</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>더 스퀘어</td>\n",
       "      <td>The Square</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>나를 차버린 스파이</td>\n",
       "      <td>The Spy Who Dumped Me</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>주피터스 문</td>\n",
       "      <td>Jupiter's Moon</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>휘트니</td>\n",
       "      <td>Whitney</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>원초적 비디오 테이프</td>\n",
       "      <td>Amateur</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>목격자</td>\n",
       "      <td>The Witness</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>공작</td>\n",
       "      <td>The Spy Gone North</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>너의 결혼식</td>\n",
       "      <td>On Your Wedding Day</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>몬스터 헌트2: 요괴사냥단</td>\n",
       "      <td>Monster Hunt 2</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>몬스터 호텔 3</td>\n",
       "      <td>Hotel Transylvania 3: A Monster Vacation</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉예정</td>\n",
       "      <td>더 시크릿 하우스</td>\n",
       "      <td>Marrowbone</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉</td>\n",
       "      <td>훔쳐보는 쉐어 하우스</td>\n",
       "      <td>Girls Share A Flat 4</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉</td>\n",
       "      <td>해외유학녀의 마사지</td>\n",
       "      <td>Populer beauty massage into a study abroad fru...</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉</td>\n",
       "      <td>폭주미망인-다빌려드립니다</td>\n",
       "      <td>Widow boarding house? I also lend a valley</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>개봉</td>\n",
       "      <td>정사 : 친구의 엄마 2 무삭제</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017</td>\n",
       "      <td>개봉</td>\n",
       "      <td>인형같은 애인클럽</td>\n",
       "      <td>Makeover dolls Fingertips that love limbs</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>20대 같은 40대 미시녀</td>\n",
       "      <td>The reason I remove the wedding ring</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>여형사의 은밀한 수사</td>\n",
       "      <td>Marubou no Onna</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>어쌔신 크리드</td>\n",
       "      <td>Assassin's Creed</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>세상의 모든 엄마와 딸들</td>\n",
       "      <td>Mothers and Daughters</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>2001</td>\n",
       "      <td>개봉</td>\n",
       "      <td>반지의 제왕 : 반지원정대 (확장판)</td>\n",
       "      <td>The Lord Of The Rings : The Fellowship Of The ...</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>너브</td>\n",
       "      <td>Nerve</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>사랑하기 때문에</td>\n",
       "      <td>BECAUSE I LOVE YOU</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>옆집 여자: 처음엔 거부 나증엔 신음</td>\n",
       "      <td>Namaikinadantituma</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>밀애: 시아버지</td>\n",
       "      <td>Mesunonioi</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>리벤지포르노 페인트 잇 블랙</td>\n",
       "      <td>Revenge Porno PAINT IT BLACK</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>내 아내의 불륜</td>\n",
       "      <td>Soputotuma</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>추천 극상 오일마사지</td>\n",
       "      <td>Suddenly, I meet with my son. We rut. Satsuki ...</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>일본 온천 여행기</td>\n",
       "      <td>The dairy of lonely woman Beautifully bloom in...</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>엘리미네이터</td>\n",
       "      <td>Eliminators</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>2014</td>\n",
       "      <td>개봉</td>\n",
       "      <td>소림사 무림 탐정-취의전장</td>\n",
       "      <td>Murger at the Lending House</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>선녀 강림 - 평화를 위해</td>\n",
       "      <td>Sexy girl party 4</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>패신저스</td>\n",
       "      <td>PASSENGERS</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>야쿠자의 여자: 은밀한 유혹</td>\n",
       "      <td>Japanese mafia Women 7</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>쇼다운 인 마닐라</td>\n",
       "      <td>Showdown in Manila</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>사다코 대 카야코</td>\n",
       "      <td>Sadako vs Kayako</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>2013</td>\n",
       "      <td>개봉</td>\n",
       "      <td>비밀객잔의 결투</td>\n",
       "      <td>The Expert of Gangster Inn</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>더 마인즈 아이</td>\n",
       "      <td>The Mind's Eye</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>굶주린 여신: 양기흡수</td>\n",
       "      <td>Eromegami</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>하드코어 미망인</td>\n",
       "      <td>Sexy girl party 5</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>2016</td>\n",
       "      <td>개봉</td>\n",
       "      <td>중년남과 고양이 여인의 동거</td>\n",
       "      <td>Domestic cat</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>여간호사의 쾌감</td>\n",
       "      <td>Sexy nurse 3</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>2012</td>\n",
       "      <td>개봉</td>\n",
       "      <td>엑소시즘 2017</td>\n",
       "      <td>Evil Born (12/12/12)</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>선배부인과 비밀공유</td>\n",
       "      <td>The glossy and beautifl widow \"I'm sorry, hone...</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>불륜녀의 황홀한 입맞춤</td>\n",
       "      <td>Affair party</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>2015</td>\n",
       "      <td>개봉</td>\n",
       "      <td>대머리 오일마사지사</td>\n",
       "      <td>Lonely aunt Confessions of abstinence Miku Aoki</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2827 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      produce_year produce_state                 title  \\\n",
       "0             2017          개봉예정               할로우 차일드   \n",
       "1             2016          개봉예정               죽음의 리무진   \n",
       "2             2018          개봉예정     극장판 도라에몽: 진구의 보물섬   \n",
       "3             2018          개봉예정      명탐정 코난 : 제로의 집행인   \n",
       "4             2017          개봉예정               살아남은 아이   \n",
       "5             2018            개봉              인공지능 섹스돌   \n",
       "6             2018            개봉                엄마의 유혹   \n",
       "7             2018            개봉         섹스-이웃집 여자-감독판   \n",
       "8             2017            개봉   부드러운 여주인:단단한 물건을 원해   \n",
       "9             2016            개봉          동창회:그녀와 하던 날   \n",
       "10            2018            개봉                금지된 섹스   \n",
       "11            2018          개봉예정                맘마미아!2   \n",
       "12            2017          개봉예정              산책하는 침략자   \n",
       "13            2017          개봉예정                   호스틸   \n",
       "14            2017          개봉예정                 더 스퀘어   \n",
       "15            2017          개봉예정            나를 차버린 스파이   \n",
       "16            2017          개봉예정                주피터스 문   \n",
       "17            2018          개봉예정                   휘트니   \n",
       "18            2016            개봉           원초적 비디오 테이프   \n",
       "19            2017          개봉예정                   목격자   \n",
       "20            2017          개봉예정                    공작   \n",
       "21            2017          개봉예정                너의 결혼식   \n",
       "22            2017          개봉예정        몬스터 헌트2: 요괴사냥단   \n",
       "23            2018          개봉예정              몬스터 호텔 3   \n",
       "24            2017          개봉예정             더 시크릿 하우스   \n",
       "25            2017            개봉           훔쳐보는 쉐어 하우스   \n",
       "26            2017            개봉            해외유학녀의 마사지   \n",
       "27            2017            개봉         폭주미망인-다빌려드립니다   \n",
       "28            2018            개봉     정사 : 친구의 엄마 2 무삭제   \n",
       "29            2017            개봉             인형같은 애인클럽   \n",
       "...            ...           ...                   ...   \n",
       "2797          2015            개봉        20대 같은 40대 미시녀   \n",
       "2798          2016            개봉           여형사의 은밀한 수사   \n",
       "2799          2016            개봉               어쌔신 크리드   \n",
       "2800          2016            개봉         세상의 모든 엄마와 딸들   \n",
       "2801          2001            개봉  반지의 제왕 : 반지원정대 (확장판)   \n",
       "2802          2016            개봉                    너브   \n",
       "2803          2016            개봉              사랑하기 때문에   \n",
       "2804          2016            개봉  옆집 여자: 처음엔 거부 나증엔 신음   \n",
       "2805          2016            개봉              밀애: 시아버지   \n",
       "2806          2016            개봉       리벤지포르노 페인트 잇 블랙   \n",
       "2807          2016            개봉              내 아내의 불륜   \n",
       "2808          2015            개봉           추천 극상 오일마사지   \n",
       "2809          2015            개봉             일본 온천 여행기   \n",
       "2810          2015            개봉                엘리미네이터   \n",
       "2811          2014            개봉        소림사 무림 탐정-취의전장   \n",
       "2812          2015            개봉        선녀 강림 - 평화를 위해   \n",
       "2813          2016            개봉                  패신저스   \n",
       "2814          2016            개봉       야쿠자의 여자: 은밀한 유혹   \n",
       "2815          2016            개봉             쇼다운 인 마닐라   \n",
       "2816          2016            개봉             사다코 대 카야코   \n",
       "2817          2013            개봉              비밀객잔의 결투   \n",
       "2818          2015            개봉              더 마인즈 아이   \n",
       "2819          2016            개봉          굶주린 여신: 양기흡수   \n",
       "2820          2015            개봉              하드코어 미망인   \n",
       "2821          2016            개봉       중년남과 고양이 여인의 동거   \n",
       "2822          2015            개봉              여간호사의 쾌감   \n",
       "2823          2012            개봉             엑소시즘 2017   \n",
       "2824          2015            개봉            선배부인과 비밀공유   \n",
       "2825          2015            개봉          불륜녀의 황홀한 입맞춤   \n",
       "2826          2015            개봉            대머리 오일마사지사   \n",
       "\n",
       "                                              title_Eng  show_time  \n",
       "0                                      The Hollow Child       88.0  \n",
       "1                                          Glass Coffin       75.0  \n",
       "2                                                   NaN      107.0  \n",
       "3                    Detective Conan: Zero the Enforcer      110.0  \n",
       "4                                            Last Child      123.0  \n",
       "5                                                   NaN       79.0  \n",
       "6                                                   NaN       80.0  \n",
       "7                                                   NaN       75.0  \n",
       "8                                           Okamisan 01       64.0  \n",
       "9                                            Rape Gurui       54.0  \n",
       "10                                                  NaN       86.0  \n",
       "11                          MAMMA MIA! HERE WE GO AGAIN      113.0  \n",
       "12                                     Before We Vanish      130.0  \n",
       "13                                              Hostile       83.0  \n",
       "14                                           The Square      151.0  \n",
       "15                                The Spy Who Dumped Me        NaN  \n",
       "16                                       Jupiter's Moon      128.0  \n",
       "17                                              Whitney      119.0  \n",
       "18                                              Amateur       93.0  \n",
       "19                                          The Witness      111.0  \n",
       "20                                   The Spy Gone North      137.0  \n",
       "21                                  On Your Wedding Day      110.0  \n",
       "22                                       Monster Hunt 2      110.0  \n",
       "23             Hotel Transylvania 3: A Monster Vacation       97.0  \n",
       "24                                           Marrowbone      110.0  \n",
       "25                                 Girls Share A Flat 4       60.0  \n",
       "26    Populer beauty massage into a study abroad fru...       63.0  \n",
       "27           Widow boarding house? I also lend a valley       61.0  \n",
       "28                                                  NaN       81.0  \n",
       "29            Makeover dolls Fingertips that love limbs       63.0  \n",
       "...                                                 ...        ...  \n",
       "2797               The reason I remove the wedding ring       62.0  \n",
       "2798                                    Marubou no Onna       72.0  \n",
       "2799                                   Assassin's Creed      115.0  \n",
       "2800                              Mothers and Daughters       92.0  \n",
       "2801  The Lord Of The Rings : The Fellowship Of The ...      228.0  \n",
       "2802                                              Nerve       96.0  \n",
       "2803                                 BECAUSE I LOVE YOU      110.0  \n",
       "2804                                 Namaikinadantituma       51.0  \n",
       "2805                                         Mesunonioi       51.0  \n",
       "2806                       Revenge Porno PAINT IT BLACK       73.0  \n",
       "2807                                         Soputotuma       52.0  \n",
       "2808  Suddenly, I meet with my son. We rut. Satsuki ...       63.0  \n",
       "2809  The dairy of lonely woman Beautifully bloom in...       56.0  \n",
       "2810                                        Eliminators       94.0  \n",
       "2811                        Murger at the Lending House       91.0  \n",
       "2812                                  Sexy girl party 4       60.0  \n",
       "2813                                         PASSENGERS      116.0  \n",
       "2814                             Japanese mafia Women 7       71.0  \n",
       "2815                                 Showdown in Manila       89.0  \n",
       "2816                                   Sadako vs Kayako       98.0  \n",
       "2817                         The Expert of Gangster Inn       91.0  \n",
       "2818                                     The Mind's Eye       87.0  \n",
       "2819                                          Eromegami       64.0  \n",
       "2820                                  Sexy girl party 5       60.0  \n",
       "2821                                       Domestic cat       62.0  \n",
       "2822                                       Sexy nurse 3       60.0  \n",
       "2823                               Evil Born (12/12/12)       85.0  \n",
       "2824  The glossy and beautifl widow \"I'm sorry, hone...       54.0  \n",
       "2825                                       Affair party       60.0  \n",
       "2826    Lonely aunt Confessions of abstinence Miku Aoki       63.0  \n",
       "\n",
       "[2827 rows x 5 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#기존데이터 변형\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': range(1, 11), 'B': np.random.randn(10)})\n",
    "df\n",
    "\n",
    "df_1 = df.copy()\n",
    "df_1.assign(ln_A = lambda x: np.log(x.A)) #로그값을 할당해서 새로운 행으로 만들기 - 메소드방식\n",
    "\n",
    "#위와 동일 일반방식\n",
    "df_2 = df.copy()\n",
    "df_2['ln_A'] = np.log(df_2['A']) \n",
    "df_2\n",
    "\n",
    "movie = pd.read_csv('D:/pandas/실습자료/실습자료/data/korea_movie_list.csv',encoding='cp949')\n",
    "\n",
    "movie_ = pd.concat([movie.filter(like='prod'), movie.filter(like='title')], axis=1)\n",
    "#필터를 통해 prod, title 성분을 가지고 있는 열들을 axis=1을 통해 열로 뽑아와서 concat으로 합치는 것임\n",
    "movie_\n",
    "#못땡겨온 열 가져와야겠다\n",
    "movie_.assign(show_time=movie['show_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>group_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  group_val\n",
       "a     0        3.5\n",
       "a     2        3.5\n",
       "a     3        3.5\n",
       "b     1        7.0\n",
       "b     4        7.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.21 - 데이터통합\n",
    "\n",
    "#중복되는 key 끼리의 value 병합\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#key기준\n",
    "\n",
    "#1\n",
    "df1 = pd.DataFrame({'key':list('bbacaab'), 'data1':range(7)})\n",
    "df2 = pd.DataFrame({'key':list('abd'), 'data2':range(3)})\n",
    "\n",
    "pd.merge(df1, df2) #아무것도 안나온다 - 왜? 단순히 합치는 게 아니라서..!\n",
    "pd.merge(df1, df2, on='key') #중복나는 key에 대해서만 가져온다 c,d는 자동으로 빠지지 dafault how='inner'-교집합\n",
    "pd.merge(df1, df2, on='key', how='outer') #중복안나는 것들도 다 가져온다 Nan으로 인해 플로팅으로 가져온다 -합집함\n",
    "\n",
    "pd.merge(df1, df2, on='key', how='left') #중복 안나는 것을 왼쪽에서만 가져온다 ->오른쪽만 플로팅 되겠지\n",
    "pd.merge(df1, df2, on='key', how='right') #중복 안나는 것을 오른쪽에서만 가져온다 ->왼쪽만 플로팅 되겠지\n",
    "# 예제를 a,b,c,d로 드니까 이해하기 어렵다. a가 각각 뭐 이름, b가 부서, c가 지출 이런식으로 생각하면 된다\n",
    "\n",
    "#2\n",
    "df3 = pd.DataFrame({'key':list('abbcaab'), 'data3':range(7)})\n",
    "df4 = pd.DataFrame({'key':list('ababd'), 'data4':range(5)})\n",
    "\n",
    "pd.merge(df3, df4, on='key') #아! 위에 a가 3개 밑에 2개 니까 3*2=6개만큼 a키 행이 생기는 거네\n",
    "#실제로는 이렇게 쓰일일 없지\n",
    "\n",
    "#3\n",
    "df5 = pd.DataFrame({'lkey':list('abbcaab'), 'data5':range(7)})\n",
    "df6 = pd.DataFrame({'rkey':list('ababd'), 'data6':range(5)})\n",
    "\n",
    "pd.merge(df5, df6, left_on='lkey', right_on='rkey') #키분리\n",
    "\n",
    "\n",
    "#index기준 - 쓰기 더 깔끔하다\n",
    "\n",
    "#4\n",
    "left = pd.DataFrame({'key':list('abaabc'), 'data':range(6)})\n",
    "right = pd.DataFrame({'group_val':[3.5, 7]}, index=['a', 'b'])\n",
    "\n",
    "pd.merge(left, right, left_on='key', right_index=True) #왼쪽은 인덱스가 없어 지정해주고, 오른쪽은 인덱스를 그대로 쓰겠다 임\n",
    "#숫자로된 전체인덱스가 있다\n",
    "\n",
    "#아니면이렇게\n",
    "left = left.set_index('key')\n",
    "pd.merge(left, right, left_index=True, right_index=True)\n",
    "#키를 인덱스로 쓰겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>계</th>\n",
       "      <td>49,540</td>\n",
       "      <td>49,773</td>\n",
       "      <td>50,515</td>\n",
       "      <td>50,734</td>\n",
       "      <td>50,948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>서울</th>\n",
       "      <td>10,201</td>\n",
       "      <td>10,208</td>\n",
       "      <td>10,312</td>\n",
       "      <td>10,250</td>\n",
       "      <td>10,195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부산</th>\n",
       "      <td>3,565</td>\n",
       "      <td>3,543</td>\n",
       "      <td>3,568</td>\n",
       "      <td>3,551</td>\n",
       "      <td>3,538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대구</th>\n",
       "      <td>2,493</td>\n",
       "      <td>2,489</td>\n",
       "      <td>2,512</td>\n",
       "      <td>2,508</td>\n",
       "      <td>2,506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인천</th>\n",
       "      <td>2,693</td>\n",
       "      <td>2,710</td>\n",
       "      <td>2,758</td>\n",
       "      <td>2,801</td>\n",
       "      <td>2,844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>광주</th>\n",
       "      <td>1,423</td>\n",
       "      <td>1,433</td>\n",
       "      <td>1,455</td>\n",
       "      <td>1,463</td>\n",
       "      <td>1,469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대전</th>\n",
       "      <td>1,481</td>\n",
       "      <td>1,484</td>\n",
       "      <td>1,504</td>\n",
       "      <td>1,516</td>\n",
       "      <td>1,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>울산</th>\n",
       "      <td>1,112</td>\n",
       "      <td>1,114</td>\n",
       "      <td>1,126</td>\n",
       "      <td>1,136</td>\n",
       "      <td>1,147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>세종</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경기</th>\n",
       "      <td>11,292</td>\n",
       "      <td>11,460</td>\n",
       "      <td>11,787</td>\n",
       "      <td>11,937</td>\n",
       "      <td>12,093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>강원</th>\n",
       "      <td>1,509</td>\n",
       "      <td>1,512</td>\n",
       "      <td>1,530</td>\n",
       "      <td>1,536</td>\n",
       "      <td>1,539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>충북</th>\n",
       "      <td>1,520</td>\n",
       "      <td>1,527</td>\n",
       "      <td>1,549</td>\n",
       "      <td>1,563</td>\n",
       "      <td>1,566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>충남</th>\n",
       "      <td>2,019</td>\n",
       "      <td>2,037</td>\n",
       "      <td>2,075</td>\n",
       "      <td>2,101</td>\n",
       "      <td>2,029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>전북</th>\n",
       "      <td>1,856</td>\n",
       "      <td>1,854</td>\n",
       "      <td>1,869</td>\n",
       "      <td>1,874</td>\n",
       "      <td>1,873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>전남</th>\n",
       "      <td>1,919</td>\n",
       "      <td>1,913</td>\n",
       "      <td>1,918</td>\n",
       "      <td>1,914</td>\n",
       "      <td>1,910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경북</th>\n",
       "      <td>2,674</td>\n",
       "      <td>2,669</td>\n",
       "      <td>2,690</td>\n",
       "      <td>2,699</td>\n",
       "      <td>2,698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경남</th>\n",
       "      <td>3,225</td>\n",
       "      <td>3,250</td>\n",
       "      <td>3,291</td>\n",
       "      <td>3,309</td>\n",
       "      <td>3,319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>제주</th>\n",
       "      <td>561</td>\n",
       "      <td>562</td>\n",
       "      <td>571</td>\n",
       "      <td>576</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2008    2009    2010    2011    2012\n",
       "계   49,540  49,773  50,515  50,734  50,948\n",
       "서울  10,201  10,208  10,312  10,250  10,195\n",
       "부산   3,565   3,543   3,568   3,551   3,538\n",
       "대구   2,493   2,489   2,512   2,508   2,506\n",
       "인천   2,693   2,710   2,758   2,801   2,844\n",
       "광주   1,423   1,433   1,455   1,463   1,469\n",
       "대전   1,481   1,484   1,504   1,516   1,525\n",
       "울산   1,112   1,114   1,126   1,136   1,147\n",
       "세종       -       -       -       -     113\n",
       "경기  11,292  11,460  11,787  11,937  12,093\n",
       "강원   1,509   1,512   1,530   1,536   1,539\n",
       "충북   1,520   1,527   1,549   1,563   1,566\n",
       "충남   2,019   2,037   2,075   2,101   2,029\n",
       "전북   1,856   1,854   1,869   1,874   1,873\n",
       "전남   1,919   1,913   1,918   1,914   1,910\n",
       "경북   2,674   2,669   2,690   2,699   2,698\n",
       "경남   3,225   3,250   3,291   3,309   3,319\n",
       "제주     561     562     571     576     584"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "korea_2012 = pd.read_excel('D:/pandas/실습자료/실습자료/data/korea_pop_2012.xls', encoding='cp949')\n",
    "korea_2012\n",
    "#unnamed 처리하자 - 엑셀가져오는과정에서오류?인듯\n",
    "korea_2012.columns = ['', '2008', '2009', '2010', '2011', '2012'] #칼럼명재조정\n",
    "korea_2012.index = korea_2012[''] #''열을 인덱스로 추가\n",
    "korea_2012 = korea_2012.drop([''],axis = 1) #원래있던''은 없애기\n",
    "korea_2012\n",
    "\n",
    "korea_2017 = pd.read_excel('D:/pandas/실습자료/실습자료/data/korea_pop_2017.xls', index_col=0, encoding='cp949') #훨간단\n",
    "korea_2017\n",
    "\n",
    "korea_2017.index == korea_2012.index #인덱스가 똑같다\n",
    "#인덱스기준병합\n",
    "korea_pop = pd.merge(korea_2012, korea_2017, left_index=True, right_index=True)\n",
    "korea_pop\n",
    "\n",
    "korea_pop.get_dtype_counts() #10개 열의 자료형은 모두 오브젝트임 (콤마, - 때문일것)\n",
    "\n",
    "#숫자형으로 바꾸기위한 전처리\n",
    "\n",
    "for i in range(0,18) :\n",
    "    a = korea_pop.iloc[i].str.replace(',','')\n",
    "    korea_pop.iloc[i] = a\n",
    "#돌면서 콤마 없애기 \n",
    "\n",
    "for i in range(0,18) :\n",
    "    a = korea_pop.iloc[i].str.replace('-','NaN') #여기서 NaN이 그냥 문자열이다\n",
    "    korea_pop.iloc[i] = a\n",
    "# -부분 처리\n",
    "\n",
    "#아직까지는 Nan이 문자열이기 때문에 정수로 바꿀 수 없다. 누락값으로 만들고 누락값 처리를 한 뒤 정수로 바꾼다\n",
    "\n",
    "korea_pop = korea_pop.astype('float64') #float으로 바꿔주면서 NaN이 누락값이된다\n",
    "korea_pop = korea_pop.fillna(0) #누락값 0 으로\n",
    "korea_pop = korea_pop.astype('int64') #이제 정수로\n",
    "\n",
    "korea_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>키</th>\n",
       "      <th>값</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>봄</td>\n",
       "      <td>0.171517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>여름</td>\n",
       "      <td>-1.070463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가을</td>\n",
       "      <td>-1.564701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>겨울</td>\n",
       "      <td>1.806110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여름</td>\n",
       "      <td>-2.044110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>겨울</td>\n",
       "      <td>-0.201447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>기타</td>\n",
       "      <td>2.096000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    키         값\n",
       "0   봄  0.171517\n",
       "1  여름 -1.070463\n",
       "2  가을 -1.564701\n",
       "3  겨울  1.806110\n",
       "0  여름 -2.044110\n",
       "2  겨울 -0.201447\n",
       "3  기타  2.096000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQL\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame({'키': ['봄', '여름', '가을', '겨울'], '값': np.random.randn(4)})\n",
    "df2 = pd.DataFrame({'키': ['여름', '겨울', '겨울', '기타'], '값': np.random.randn(4)})\n",
    "\n",
    "#SQL문장에서 사용되는 조인과 데이터프레임에서 사용하는 방식이 같다.\n",
    "\n",
    "\"\"\"\n",
    "SELECT *\n",
    "FROM df1\n",
    "INNER JOIN df2\n",
    "    ON df1.key = df2.key;\n",
    "\"\"\"\n",
    "pd.merge(df1, df2, on='키') #default how가 inner\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "SELECT *\n",
    "FROM df1\n",
    "LEFT OUTER JOIN df2\n",
    "    ON df1.key = df2.key;\n",
    "\"\"\"\n",
    "pd.merge(df1, df2, on='키', how='left')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "SELECT *\n",
    "FROM df1\n",
    "FULL OUTER JOIN df2\n",
    "    ON df1.key = df2.key;\n",
    "\"\"\"\n",
    "pd.merge(df1, df2, on='키', how='outer')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "SELECT city, rank\n",
    "FROM df1\n",
    "UNION ALL\n",
    "SELECT city, rank\n",
    "FROM df2;\n",
    "\"\"\"\n",
    "pd.concat([df1, df2])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "SELECT city, rank\n",
    "FROM df1\n",
    "UNION\n",
    "SELECT city, rank\n",
    "FROM df2;\n",
    "\"\"\"\n",
    "df2.loc[1] = df1.loc[3]\n",
    "pd.concat([df1, df2]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>서울</th>\n",
       "      <th>부산</th>\n",
       "      <th>대구</th>\n",
       "      <th>인천</th>\n",
       "      <th>광주</th>\n",
       "      <th>대전</th>\n",
       "      <th>울산</th>\n",
       "      <th>세종</th>\n",
       "      <th>경기</th>\n",
       "      <th>강원</th>\n",
       "      <th>충북</th>\n",
       "      <th>충남</th>\n",
       "      <th>전북</th>\n",
       "      <th>전남</th>\n",
       "      <th>경북</th>\n",
       "      <th>경남</th>\n",
       "      <th>제주</th>\n",
       "      <th>합계</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14 의복, 의복 액세서리 및 모피제품 제조업</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           서울  부산  대구  인천  광주  대전  울산  세종  경기  강원  충북  충남  전북  \\\n",
       "14 의복, 의복 액세서리 및 모피제품 제조업  41   3   0   3   2   0   0   0  17   0   0   0   5   \n",
       "\n",
       "                           전남  경북  경남  제주  합계  \n",
       "14 의복, 의복 액세서리 및 모피제품 제조업   1   0   0   0  72  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예제, SQL조건문\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "korea_2018 = pd.read_excel('D:/pandas/실습자료/실습자료/data/factory_reg_2018.xlsx',sheet_name=2, header=[2,3], index_col=0, encoding='cp949')\n",
    "korea_2018\n",
    "\n",
    "korea_2018 = korea_2018.dropna()\n",
    "korea_2018\n",
    "\n",
    "korea_2018.get_dtype_counts() #초기 Nan행으로 인해 합계열 빼고는 float type\n",
    "korea_2018 = korea_2018.astype('int64')\n",
    "korea_2018.get_dtype_counts()\n",
    "\n",
    "korea_2018.columns.levels[0]\n",
    "korea_2018.columns.levels[1]\n",
    "\n",
    "korea_2018.columns = ['서울','부산','대구','인천','광주','대전','울산','세종','경기','강원','충북','충남','전북','전남','경북','경남','제주','합계']\n",
    "korea_2018.columns\n",
    "\n",
    "#열 레이블에 특정 이름이 포함되어 있는지를 확인\n",
    "korea_2018.columns.isin(['서울','제주']) \n",
    "\n",
    "#True인 열 둘만 뽑아다가 복사 -> 왜 이렇게? 실제 빅데이터상으로 문서를 체크해서 이것들을 일일이 확인할 수 없으니까?\n",
    "korea_2018_서울_제주 = korea_2018.iloc[:,korea_2018.columns.isin(['서울','제주'])]\n",
    "korea_2018_서울_제주\n",
    "\n",
    "korea_2018_서울_제주.서울.between(10, 20).sum() #서울중에서 10과 20사이의 숫자가 몇개\n",
    "korea_2018_서울_제주.loc[korea_2018_서울_제주.서울.between(10, 20),'서울'] #고놈을 출력해보자\n",
    "\n",
    "#쿼리문으로 해볼까?\n",
    "korea_2018.query('서울 >=10 & 서울 <= 20').서울\n",
    "korea_2018.query('서울 >=10 & 서울 <= 20')['서울'] #동일\n",
    "korea_2018.query('서울 >=10 & 서울 <= 20')[['서울']] #팬시!\n",
    "\n",
    "mm = 10\n",
    "nn = 20\n",
    "qs1 = \"@mm <= 서울 <= @nn \"\n",
    "korea_2018.query(qs1)[['서울']]\n",
    "# 보통요렇게 많이한다구\n",
    "\n",
    "#다른 메소드 - where\n",
    "korea_2018.where(korea_2018['서울'] < 30) #서울 열에서 30보다 작은곳찾고, 30보다 크면 해당 행을 싹다 NaN으로 처리한다 그래서 float\n",
    "korea_2018.where(korea_2018['서울'] < 30, 0) #동일 - 해당 행을 싹다 0으로 처리하기 때문에 int\n",
    "\n",
    "#다른 메소드 - mask\n",
    "korea_2018.mask(korea_2018['서울'] < 30) #where과 반대. 30보다 작은 곳을 Nan처리\n",
    "korea_2018.mask(korea_2018['서울'] < 30, 0.0) #동일 - 0처리\n",
    "\n",
    "korea_2018.take([0],axis=0) #첫행만 가져오자\n",
    "korea_2018.take([0,3,5],axis=1).head() #0,3,5 열만가져오자\n",
    "\n",
    "#SQL로?\n",
    "\"\"\"\n",
    "SELECT 서울, 인천, 대전\n",
    "FROM korea_2018\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "korea_2018[['서울', '인천', '대전']].head()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "SELECT * \n",
    "FROM korea_2018\n",
    "WHERE 서울 = 41;\n",
    "\"\"\"\n",
    "korea_2018[korea_2018['서울'] == 41 ] #서울이 41인 행출력\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "SELECT * \n",
    "FROM korea_2018 \n",
    "WHERE 서울 < 41 & 제주 > 5 ;\n",
    "\"\"\"\n",
    "korea_2018[(korea_2018['서울'] < 41) &  (korea_2018['제주'] > 0)]\n",
    "#or\n",
    "is_41 = korea_2018['서울'] == 41\n",
    "is_41\n",
    "is_41.value_counts()\n",
    "korea_2018[is_41] #조금상세한방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# 그룹화처리\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "book_data = pd.read_csv(\"D:/pandas/실습자료/실습자료/data/book_data.csv\",encoding='cp949')\n",
    "book_data\n",
    "\n",
    "#전처리과정\n",
    "book_data.count()\n",
    "\n",
    "book_data.book_date.max() #이상한놈등장\n",
    "book_data.book_date.replace('초판출간 2008년', '2018-01-01',inplace=True) #처리\n",
    "book_data.book_date.max()\n",
    "\n",
    "book_data.book_cover.value_counts()\n",
    "book_data.book_cover.fillna(\"반양장본\",inplace=True)\n",
    "book_data.book_cover.value_counts()\n",
    "\n",
    "book_data.book_size.value_counts()\n",
    "book_data.book_size.fillna('128*188mm',inplace=True)\n",
    "book_data.book_size.value_counts()\n",
    "\n",
    "book_data.count() #perfect!\n",
    "\n",
    "book_data.book_publisher.value_counts() #출판사빈도\n",
    "book_data.book_publisher.value_counts().shape #출판사 다양성 880개 너무많아\n",
    "book_data.book_price.value_counts() #가격빈도\n",
    "book_data.book_price.value_counts().shape #가격다양성 - 171가지 굿\n",
    "\n",
    "#본론!! (1)\n",
    "book_data_gr = book_data.groupby('book_price') #가격을 기준으로 그룹을짓자\n",
    "type(book_data_gr) #DataFrameGroupBy클래스!!\n",
    "\n",
    "book_data_gr.ngroups #총 몇그룹? 171\n",
    "book_data_gr.groups #그룹 모아보기\n",
    "type(book_data_gr.groups) #각 그룹의 타입\n",
    "book_data_gr.groups.keys() #그룹으로 묶인 실제 정보 중 내부에 있는 키값(가격 정보)만 불러오기\n",
    "\n",
    "book_data_gr.groups['10,080'] #그중 10080인놈은 무슨행인가\n",
    "book_data_gr.groups['10,080'].size #몇개인가\n",
    "book_data_gr.get_group('10,080') #DF로 보기\n",
    "\n",
    "#판매량을 정수로 바꿔보자\n",
    "book_data.sales_point.dtype #현재 문자열\n",
    "\n",
    "#그전에! 문자열을 제거할 때 정수형 자료형을 가진 열을 반환하면 문제가 있다 그래서 다른 변수에 저장한 후에 나중에 가져올 것이다\n",
    "book_data.book_weight.dtype #int\n",
    "book_weight = book_data.book_weight #복사\n",
    "\n",
    "# 단, 원래라면 book_data.book_page 도 정수여야하지만\n",
    "# book_data.book_weight.dtype 해보면 object\n",
    "# book_data.book_page.max() 로 이상한놈을 찾고 그놈을 없애주고 나서해야함\n",
    "\n",
    "# 콤마없애기 - 타입바꾸기전처리 \n",
    "for i in range(0,2000) :\n",
    "    a = book_data.iloc[i].str.replace(',','') \n",
    "    book_data.iloc[i] = a\n",
    "#여기서 book_weight 값들이 사라짐 왜냐하면 각 행마다 replace처리를 해서 반환했는데\n",
    "#현재 나머지 열들은 모두 object니까 object기준으로 반환을 한다\n",
    "#object기준에서 int형은 아무것도 아니고 그래서 대신 Nan을 쭉 반환하는 것\n",
    "    \n",
    "book_data.sales_point = book_data.sales_point.astype('float64') #공백을 Nan으로\n",
    "book_data.book_weight.dtype\n",
    "#Nan을 0으로 바꾼뒤 정수로 바꾸기도 했었지?\n",
    "book_data\n",
    "\n",
    "#이제 다시 weight 가져오자\n",
    "book_data.book_weight = book_weight\n",
    "book_data\n",
    "\n",
    "#(2-1) 북커버, 북데이트 기준으로 그룹화해볼까\n",
    "book_data.groupby('book_cover').agg({'book_name':'count', 'sales_point':'mean', 'book_weight':'mean'})\n",
    "book_new = book_data.groupby('book_date').agg({'book_name':'count', 'sales_point':'mean', 'book_weight':'mean'})\n",
    "book_new = book_new.sort_index() #안해도정렬됨\n",
    "book_new\n",
    "\n",
    "book_new.columns = ['book_count','sales_point', 'book_weight']\n",
    "\n",
    "book_new.nlargest(5,columns='book_count')\n",
    "book_new.nsmallest(5,columns='book_count') #북카운트열 기준 최솟값 다섯개 위에서부터(디폴트)\n",
    "\n",
    "#여러개의 열을 동시에 그룹화\n",
    "group_cols = ['book_date','book_cover'] #멀티인덱스\n",
    "agg_cols=['sales_point','book_weight'] #상위열\n",
    "cols=['sum','mean','size'] #하위열\n",
    "fg = book_data.groupby(group_cols)[agg_cols].agg(cols)\n",
    "fg\n",
    "\n",
    "level1 = fg.columns.get_level_values(0)\n",
    "level1\n",
    "level2 = fg.columns.get_level_values(1)\n",
    "level2\n",
    "fg.columns = level1 + '_' + level2 #두개의 층 모두 문자열이므로 이방식을 통해 단일인덱스로 변경- 칼럼 속성을 대체!\n",
    "fg\n",
    "\n",
    "#(2-2) 내부에 수학 함수를 넣거나 사용자 함수를 넣어서 계산할때는 transform메소드를 사용해서 그룹화 가능 - 주로 단순결과를 위해서\n",
    "fg_ = book_data.groupby(group_cols)[agg_cols].transform('sum')\n",
    "fg_\n",
    "\n",
    "#transform은 사용자 정의함수 지정해서넣을수있다 (apply방식과의 차이를 보자)\n",
    "book_data.groupby(group_cols).apply(lambda x: x['sales_point']* 100)\n",
    "book_data.groupby(group_cols)['sales_point'].transform(lambda x: x * 100) #시리즈\n",
    "book_data.groupby(group_cols)[['sales_point']].transform(lambda x: x * 100) #데이터프레임 -팬시검색\n",
    "book_data.groupby(group_cols)['sales_point', 'book_weight'].transform(lambda x: x * 100) #여러 열 선택\n",
    "\n",
    "#그룹화 한 파일 새로저장\n",
    "fg.to_csv(\"D:/pandas/실습자료/실습자료/data/book_data_group.csv\", encoding='cp949')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-239-f03ff1d55fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mGROUP\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mbook_date\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \"\"\"\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mbook_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'book_date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'sales_point'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'book_date'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aggregate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataFrameGroupBy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m     \u001b[0magg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0m_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_agg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_agg_1dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_agg\u001b[1;34m(arg, func)\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magg_how\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magg_how\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_agg_1dim\u001b[1;34m(name, how, subset)\u001b[0m\n\u001b[0;32m    430\u001b[0m                     raise SpecificationError(\"nested dictionary is ambiguous \"\n\u001b[0;32m    431\u001b[0m                                              \"in aggregation\")\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcolg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_level\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0m_agg_2dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[0mcyfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_cython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcyfunc\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcyfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnkeys\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_groupby_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'numeric_only'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cython_agg_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mGroupByError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No numeric types to aggregate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_aggregated_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "#SQL그룹화\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "book_data = pd.read_csv(\"D:/pandas/실습자료/실습자료/data/book_data.csv\",encoding='cp949')\n",
    "\n",
    "\n",
    "#한 테이블에서 특정 열을 기준으로 그룹화해 내부의 개수 확인\n",
    "\"\"\"\n",
    "SELECT book_date, COUNT(*)\n",
    "FROM book_data\n",
    "GROUP BY book_date;\n",
    "\"\"\"\n",
    "book_data.groupby('book_date').size()\n",
    "book_data.groupby('book_date').count()\n",
    "book_data.groupby('book_date')['sales_point'].count()\n",
    "\n",
    "\n",
    "#특정그룹으로 묶고 평균과 개수를 처리\n",
    "\"\"\"\n",
    "SELECT book_date, AVG('sales_point'), COUNT(*)\n",
    "FROM book_data\n",
    "GROUP BY book_date;\n",
    "\"\"\"\n",
    "book_data.groupby('book_date').agg({'sales_point': np.mean, 'book_date': np.size})\n",
    "\n",
    "\n",
    "#두개의 열을 그룹화해서 두개의 열과 함수를 실행\n",
    "\"\"\"\n",
    "SELECT book_date,book_cover, COUNT(*), AVG(sales_point)\n",
    "FROM book_data\n",
    "GROUP BY book_date,book_cover;\n",
    "\"\"\"\n",
    "book_data.groupby(['book_date','book_cover']).agg({'sales_point': [np.size, np.mean]})\n",
    "\n",
    "#np.mean이 안된다 버전뭔가 문제가있나봄"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
